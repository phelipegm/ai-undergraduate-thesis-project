{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These examples and texts were inspired through the website http://leportella.com/pt-br/2017/11/30/brincando-de-nlp-com-spacy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(u'Você encontrou o livro que eu te falei, Phelipe ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um <b>doc</b> é uma sequência de objetos do tipo <b>Token</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Você',\n",
       " 'encontrou',\n",
       " 'o',\n",
       " 'livro',\n",
       " 'que',\n",
       " 'eu',\n",
       " 'te',\n",
       " 'falei,',\n",
       " 'Phelipe',\n",
       " '?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar de ser coerente a divisão por espaços, o verbo falei e a vírgula estão dentro do mesmo token. O <b>nlp</b> consegue entender a diferença entre eles. Logo, quando se utiliza os tokens dentro da estrutura do documento, temos uma divisão mais coerente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Você, encontrou, o, livro, que, eu, te, falei, ,, Phelipe, ?]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos agora uma lista de tokens, e não uma lista de strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obter a string de cada <b>Token</b>, pode-se utilizar o método .orth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Você',\n",
       " 'encontrou',\n",
       " 'o',\n",
       " 'livro',\n",
       " 'que',\n",
       " 'eu',\n",
       " 'te',\n",
       " 'falei',\n",
       " ',',\n",
       " 'Phelipe',\n",
       " '?']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entendendo a diferença entre palavras e pontuações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Você', 'encontrou', 'o', 'livro', 'que', 'eu', 'te', 'falei', 'Phelipe']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.orth_ for token in doc if not token.is_punct]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SpaCy também permite verificar a similaridade semântica entre as palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = [token for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma o tokens[0] representa o token da palavra <b>Você</b> e o tokens[5] o da palavra <b>eu</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29896945"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0].similarity(tokens[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar a similaridade entre as palavras <b>Você</b> e <b>livro</b>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06758765"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0].similarity(tokens[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelos valores, pode-se perceber que as palavras <b>Você</b> e <b>eu</b> estão semânticamente mais próximas do que <b>Você</b> e <b>livro</b> (O que faz total sentido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise de classes gramaticais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Você', 'PRON'),\n",
       " ('encontrou', 'VERB'),\n",
       " ('o', 'DET'),\n",
       " ('livro', 'NOUN'),\n",
       " ('que', 'PRON'),\n",
       " ('eu', 'PRON'),\n",
       " ('te', 'PRON'),\n",
       " ('falei', 'VERB'),\n",
       " (',', 'PUNCT'),\n",
       " ('Phelipe', 'PROPN'),\n",
       " ('?', 'PUNCT')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.orth_, token.pos_) for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempos verbais diferentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a situação em que temos um texto com o mesmo verbo sendo utilizado diversas vezes, porém em tempos verbais diferentes. A análise do texto passa a ser mais difícil. Nesse caso, deve-se analisar não o tempo verbal, mas sim sua raíz. O que ocorre da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = nlp(u'testei, testaram, testarão')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testar', ',', 'testar', ',', 'testar']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ancestrais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos checar se uma palavra é ancestral da outra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'testar, testei')\n",
    "tokens = [token for token in doc]\n",
    "tokens[0].is_ancestor(tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar as entidades presentes em um texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = nlp(u'Atualmente, o presidente Michel Temer governa o Brasil. Ele o faz diretamente do Palácio do Planalto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Michel Temer, Brasil, Palácio do Planalto)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Michel Temer, 'PER'), (Brasil, 'LOC'), (Palácio do Planalto, 'LOC')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(entity, entity.label_) for entity in doc.ents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obs.: O modelo em inglês está bem mais avançado. Logo, consegue identificar entidades bem mais complexas do que no modelo em português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Barack Obama, 'PERSON'), (American, 'NORP'), (\n",
       "       , 'PERSON'), (44th, 'ORDINAL'), (the United States,\n",
       "  'GPE'), (2009 to 2017, 'DATE'), (first, 'ORDINAL'), (\n",
       "       African American, 'NORP'), (\n",
       "       , 'PERSON'), (first, 'ORDINAL'), (United States, 'GPE')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_obama = \"\"\"Barack Obama is an American politician who served as\n",
    "     the 44th President of the United States from 2009 to 2017. He is the first\n",
    "     African American to have served as president,\n",
    "     as well as the first born outside the contiguous United States.\"\"\"\n",
    "nlp = spacy.load('en')\n",
    "nlp_obama = nlp(wiki_obama)\n",
    "[(i, i.label_) for i in nlp_obama.ents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
